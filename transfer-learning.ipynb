{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cr9FE8c7JawQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torchsummary import summary\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import progressbar\n",
        "\n",
        "# Get our VGG and Resnet models\n",
        "from torchvision.models import vgg16, vgg19, VGG16_Weights, VGG19_Weights\n",
        "from torchvision.models import resnet50, resnet152, ResNet50_Weights, ResNet152_Weights\n",
        "\n",
        "# Imports for Data\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import transforms, Resize\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "from torchvision.io import read_image\n",
        "\n",
        "DIMENSION = 224\n",
        "BATCH_SIZE = 64\n",
        "DATA_SIZE = 24000\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "widgets = [\n",
        "    ' [',\n",
        "    progressbar.Timer(format= 'elapsed time: %(elapsed)s'),\n",
        "    '] ',\n",
        "    progressbar.Bar('*'),' (',\n",
        "    progressbar.ETA(), ') ',\n",
        "]\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pW1Sg9_XWMdZ"
      },
      "outputs": [],
      "source": [
        "# Set Up Data\n",
        "preprocess = transforms.Compose([\n",
        "        transforms.Resize((DIMENSION, DIMENSION)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),])\n",
        "\n",
        "# Load data from CIFAR and trim it down\n",
        "train = CIFAR10('~/data/CIFAR', download=True, train=True, transform=preprocess)\n",
        "test = CIFAR10('~/data/CIFAR', download=True, train=False, transform=preprocess)\n",
        "train = torch.utils.data.Subset(train, list(range(0, DATA_SIZE)))\n",
        "\n",
        "# Create data loaders objects\n",
        "train_dl = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_dl = DataLoader(test, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# Take a peak at the data\n",
        "print(type(train[0][0]))\n",
        "plt.imshow(train[1][0].cpu().permute(1, 2, 0))\n",
        "print(f\"Train length x: {len(train)}, y: {len(test)}\")\n",
        "print(f\"Current Device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEORCXjpf8u5"
      },
      "outputs": [],
      "source": [
        "# Training code\n",
        "def train_batch(model, X_train, Y_train, opt, loss_func):\n",
        "\n",
        "  opt.zero_grad()                       # Flush memory\n",
        "  pred = model(X_train)\n",
        "  batch_loss = loss_func(pred, Y_train) # Compute loss\n",
        "  batch_loss.backward()                 # Compute gradients\n",
        "  opt.step()                            # Make a GD step\n",
        "\n",
        "  return batch_loss.detach().cpu().numpy()\n",
        "\n",
        "\n",
        "def accuracy(model, test_loader):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  # Set the model to evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  # Disable gradient calculation\n",
        "  print(\"Computing accuracy...\")\n",
        "  start = time.time()\n",
        "  bar = progressbar.ProgressBar(max_value=len(test_loader), widgets=widgets).start()\n",
        "  with torch.no_grad():\n",
        "      for i, batch in enumerate(test_loader):\n",
        "          inputs, labels = batch\n",
        "          inputs = inputs.to(device)  # Send inputs to the device (CPU or GPU)\n",
        "          labels = labels.to(device)  # Send labels to the device\n",
        "\n",
        "          # Forward pass\n",
        "          outputs = model(inputs)\n",
        "\n",
        "          # Get predicted class labels\n",
        "          _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "          # Update counts\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "          bar.update(i)\n",
        "\n",
        "  # Calculate accuracy\n",
        "  accuracy = (correct / total) * 100.0\n",
        "  testing_time = time.time() - start\n",
        "  return accuracy, testing_time\n",
        "\n",
        "\n",
        "def train_model(model, epochs, optimizer, loss):\n",
        "\n",
        "  # Put model in training mode\n",
        "  model.train()\n",
        "  losses, is_accuracies, os_accuracies, n_epochs = [], [], [], epochs\n",
        "  start = time.time()\n",
        "  for epoch in range(n_epochs):\n",
        "      print(f\"Running epoch {epoch + 1} of {n_epochs}\")\n",
        "      bar = progressbar.ProgressBar(max_value=len(train_dl), widgets=widgets).start()\n",
        "      epoch_losses = []\n",
        "\n",
        "      # Loop to train each batch and measure its loss value\n",
        "      for i, batch in enumerate(train_dl):\n",
        "          x, y = batch\n",
        "          x, y = x.to(device), y.to(device)\n",
        "          batch_loss = train_batch(model, x, y, optimizer, loss)\n",
        "          epoch_losses.append(batch_loss)\n",
        "          bar.update(i)\n",
        "\n",
        "      # Log and track epoch progress\n",
        "      epoch_loss = np.mean(epoch_losses)\n",
        "      losses.append(epoch_loss)\n",
        "      print()\n",
        "      print(f\"Epoch {epoch + 1} had loss of {epoch_loss}\")\n",
        "\n",
        "  training_time = time.time() - start\n",
        "  return training_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Wn_b-uwZCvv"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Code we want to run to test each model\n",
        "def test_model(model):\n",
        "  test_accuracy, inference_time = accuracy(model, test_dl)\n",
        "  print()\n",
        "  print(f\"Test Accuracy: {test_accuracy}\")\n",
        "  print(f\"Inference time: {inference_time}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFlaQpGIZK-l"
      },
      "outputs": [],
      "source": [
        "# Define and train the vgg models\n",
        "vgg_models = [\n",
        "    vgg16(weights=VGG16_Weights.IMAGENET1K_V1).to(device),\n",
        "    vgg19(weights=VGG19_Weights.IMAGENET1K_V1).to(device),\n",
        "]\n",
        "\n",
        "for model in vgg_models:\n",
        "\n",
        "  # Disable training for VGG's feature layers\n",
        "  for param in model.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "  # Set up the model with our classifier\n",
        "  model.avgpool = nn.AdaptiveAvgPool2d(output_size=(1,1)).to(device)\n",
        "  model.classifier = nn.Sequential(\n",
        "                                   nn.Linear(512,128),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.Dropout(0.2),\n",
        "                                   nn.Linear(128,10),\n",
        "                                   nn.Sigmoid()).to(device)\n",
        "  summary(model, (3, DIMENSION, DIMENSION))\n",
        "\n",
        "  # Train the model\n",
        "  loss_func = nn.CrossEntropyLoss().to(device)\n",
        "  opt = Adam(model.parameters(), lr=1e-3)\n",
        "  training_time = train_model(model, 5, opt, loss_func)\n",
        "\n",
        "  # Print some training stats\n",
        "  print(f\"Total training time: {training_time}\")\n",
        "\n",
        "  # Test the model\n",
        "  test_model(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMAd0xARZQ-V"
      },
      "outputs": [],
      "source": [
        "# Define and train the resnet models\n",
        "res_models = [\n",
        "    resnet50(weights=ResNet50_Weights.IMAGENET1K_V1).to(device),\n",
        "    resnet152(weights=ResNet152_Weights.IMAGENET1K_V1).to(device)\n",
        "]\n",
        "\n",
        "for model in res_models:\n",
        "\n",
        "  # Disable training for ResNet's feature layers\n",
        "  for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "  # Set up the model with our classifier\n",
        "  model.fc = nn.Sequential(nn.Flatten(),\n",
        "                           nn.Linear(2048,128),\n",
        "                           nn.ReLU(),\n",
        "                           nn.Dropout(0.2),\n",
        "                           nn.Linear(128,10),\n",
        "                           nn.Sigmoid()).to(device)\n",
        "  summary(model, (3, DIMENSION, DIMENSION))\n",
        "\n",
        "  # Train the model\n",
        "  loss_func = nn.CrossEntropyLoss().to(device)\n",
        "  opt = Adam(model.parameters(), lr=1e-3)\n",
        "  training_time = train_model(model, 5, opt, loss_func)\n",
        "\n",
        "  # Print some training stats\n",
        "  print(f\"Total training time: {training_time}\")\n",
        "\n",
        "  # Test the model\n",
        "  test_model(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IerJviNQsGIB"
      },
      "outputs": [],
      "source": [
        "# Test Some Images from Google\n",
        "# 2 frogs, 2 ships, 2 airplanes\n",
        "classes = {\n",
        "    0: \"airplane\",\n",
        "    1: \"automobile\",\n",
        "    2: \"bird\",\n",
        "    3: \"cat\",\n",
        "    4: \"deer\",\n",
        "    5: \"dog\",\n",
        "    6: \"frog\",\n",
        "    7: \"horse\",\n",
        "    8: \"ship\",\n",
        "    9: \"truck\"\n",
        "}\n",
        "paths = [\"frog1.png\", \"frog2.png\", \"ship1.png\", \"ship2.png\", \"plane1.png\", \"plane2.png\"]\n",
        "for path in paths:\n",
        "\n",
        "  # Get tensor from file\n",
        "  img = read_image(path)\n",
        "  img = img[:3, :, :]\n",
        "  img = to_pil_image(img)\n",
        "\n",
        "  # Preprocess the image\n",
        "  img = preprocess(img)\n",
        "\n",
        "  # Plot image\n",
        "  plt.imshow(img.permute(1, 2, 0))\n",
        "\n",
        "  # Check the predicted class\n",
        "  models = vgg_models + res_models\n",
        "  for model in models:\n",
        "    model.eval()\n",
        "    prediction = model(img[None, :, :, :].to(device))\n",
        "    prediction = classes[torch.argmax(prediction, 1).item()]\n",
        "    print(f\"Prediction for {path}: {prediction}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}